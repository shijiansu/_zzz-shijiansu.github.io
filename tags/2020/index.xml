<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Shijian Homepage – 2020</title><link>/tags/2020/</link><description>Recent content in 2020 on Shijian Homepage</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Tue, 22 Sep 2020 00:00:00 +0000</lastBuildDate><atom:link href="/tags/2020/index.xml" rel="self" type="application/rss+xml"/><item><title>Topics: 12 Factor App Principles and Cloud-Native Microservices</title><link>/topics/cloud-native/12-factor-apps/12-factor-app-principles-and-cloud-native-microservices/</link><pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate><guid>/topics/cloud-native/12-factor-apps/12-factor-app-principles-and-cloud-native-microservices/</guid><description>
&lt;blockquote>
&lt;p>&lt;a href="https://dzone.com/articles/12-factor-app-principles-and-cloud-native-microser/">https://dzone.com/articles/12-factor-app-principles-and-cloud-native-microser/&lt;/a> | 2020-09-22&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="images/12-factor-app-principles.png" alt="img">&lt;/p>
&lt;p>12-factor app is a methodology or set of principles for building the scalable and performant, independent, and most resilient enterprise applications. It establishes the general principles and guidelines for creating robust enterprise applications. 12-factor app principles got very popular as it aligns with Microservice principles.&lt;/p>
&lt;h2 id="the-12-factor-principles">The 12-Factor Principles&lt;/h2>
&lt;ul>
&lt;li>Codebase (One codebase tracked in revision control, many deploys)&lt;/li>
&lt;li>Dependencies (Explicitly declare and isolate the dependencies)&lt;/li>
&lt;li>Config (Store configurations in an environment)&lt;/li>
&lt;li>Backing Services (treat backing resources as attached resources)&lt;/li>
&lt;li>Build, release, and Run (Strictly separate build and run stages)&lt;/li>
&lt;li>Processes (execute the app as one or more stateless processes)&lt;/li>
&lt;li>Port Binding (Export services via port binding)&lt;/li>
&lt;li>Concurrency (Scale out via the process model)&lt;/li>
&lt;li>Disposability (maximize the robustness with fast startup and graceful shutdown)&lt;/li>
&lt;li>Dev/prod parity (Keep development, staging, and production as similar as possible)&lt;/li>
&lt;li>Logs (Treat logs as event streams)&lt;/li>
&lt;li>Admin processes (Run admin/management tasks as one-off processes)&lt;/li>
&lt;/ul>
&lt;h2 id="1-codebase-one-codebase-tracked-in-revision-control-many-deploys">1. Codebase (One Codebase Tracked In Revision Control, Many Deploys)&lt;/h2>
&lt;p>12-factor app advocates that every application should have its own codebase (repos). Multiple codebases for multiple versions must be avoided. Please do note that having branches would be fine. I.e. For all the deployment environments there should be only one repo but not multiple.&lt;/p>
&lt;p>Multiple apps sharing the same code are a violation of the twelve-factor. Here you should opt-in for shared libraries.&lt;/p>
&lt;p>From the 12-factor app perspective app, deploy meaning the running instance of an app like production, staging, QA, etc. Additionally, every developer has a copy of the app running in their local development environment, each of which also qualifies as a deploy.&lt;/p>
&lt;p>Different versions (the version is like a code change that is available in one environment but not in other) may be active in multiple deploys.&lt;/p>
&lt;ul>
&lt;li>Microservices: In Microservices, every service should have its own codebase. Having an independent codebase helps you to easy CI/CD process for your applications.&lt;/li>
&lt;/ul>
&lt;p>Twelve-factor app advocates of not sharing the code between the application. If you need to share you need to build a library and make it as a dependency and manage through package repository like maven.&lt;/p>
&lt;h2 id="2-dependencies-explicitly-declare-and-isolate-the-dependencies">2. Dependencies (Explicitly Declare and Isolate the Dependencies)&lt;/h2>
&lt;p>It talks about managing the dependencies externally using dependency management tools instead of adding them to your codebase.&lt;/p>
&lt;p>From the perspective of the Java, you can think of Gradle as a dependency manager. You will mention all the dependencies in build.gradle file and your application will download all the mentioned dependencies from maven repository or various other repositories.&lt;/p>
&lt;p>You also need to consider the dependencies from the operating system/ execution environment perspective as well.&lt;/p>
&lt;p>Microservices: All the application packages will be managed through package managers like sbt, maven.&lt;/p>
&lt;ul>
&lt;li>In non-containerized environments, you can go for configuration management tools like chef, ansible, etc. to install system-level dependencies.&lt;/li>
&lt;li>For a containerized environment, you can go for dockerfile.&lt;/li>
&lt;/ul>
&lt;h2 id="3-config-store-configurations-in-an-environment">3. Config (Store Configurations In an Environment&lt;/h2>
&lt;p>Anything that varies between the deployment environments is considered as configuration. This includes:&lt;/p>
&lt;ul>
&lt;li>Database connections and credentials, system integration endpoints&lt;/li>
&lt;li>Credentials to external services such as Amazon S3 or Twitter or any other external apps&lt;/li>
&lt;li>Application-specific information like IP Addresses, ports, and hostnames, etc.&lt;/li>
&lt;/ul>
&lt;p>You should not hardcode any configuration values as constants in the codebase. This is a direct violation of 12-factor app principles.&lt;/p>
&lt;p>12-factor app principles suggest saving the configuration values in the environment variables.&lt;/p>
&lt;p>It advocates the strict separation between the code and configurations. The code must be the same irrespective of where the application being deployed.&lt;/p>
&lt;p>As per &amp;ldquo;config&amp;rdquo;, what varies for the environment to the environment must be moved to configurations and managed via environment variables.&lt;/p>
&lt;ul>
&lt;li>Microservices: Externalize the configurations from the application. In a microservice service environment, you can manage the configurations for your applications from a source control like git (spring-cloud-config) and use the environment variables to not to maintain the sensitive information in the source control.&lt;/li>
&lt;/ul>
&lt;h2 id="4-backing-services-treat-backing-resources-as-attached-resources">4. Backing Services (Treat Backing Resources as Attached Resources)&lt;/h2>
&lt;p>As per 12 factor app principles, a backing service is an application/service the app consumes over the network as part of its normal operation.&lt;/p>
&lt;p>Database, Message Brokers, any other external systems that the app communicates is treated as Backing service.&lt;/p>
&lt;p>12-factor app can automatically swap the application from one provider to another without making any further modifications to the code base. Let us say, you would like to change the database server from MySQL to Aurora. To do so, you should not make any code changes to your application. Only configuration change should be able to take care of it.&lt;/p>
&lt;ul>
&lt;li>Microservices: In a microservice ecosystem, anything external to service is treated as attached resource. The resource can be swapped at any given point of time without impacting the service.&lt;/li>
&lt;/ul>
&lt;p>By following the interfaced based programming allow to swap the provider dynamically without impact on the system. Plug-in based implementation also helps you to support multiple providers.&lt;/p>
&lt;h2 id="5-build-release-and-run-strictly-separate-build-and-run-stages">5. Build, Release, and Run (Strictly Separate Build and Run Stages)&lt;/h2>
&lt;p>The application must have a strict separation between the build, release, and run stages. Let us understand each stage in more detail.&lt;/p>
&lt;ul>
&lt;li>Build stage: transform the code into an executable bundle/ build package.&lt;/li>
&lt;li>Release stage: get the build package from the build stage and combines with the configurations of the deployment environment and make your application ready to run.&lt;/li>
&lt;li>Run stage: It is like running your app in the execution environment.&lt;/li>
&lt;/ul>
&lt;p>Microservices: You can use CI/CD tools to automate the builds and deployment process. Docker images make it easy to separate the build, release, and run stages more efficiently.&lt;/p>
&lt;h2 id="6-processes-execute-the-app-as-one-or-more-stateless-processes">6. Processes (Execute the App as One or More Stateless Processes)&lt;/h2>
&lt;p>The app is executed inside the execution environment as a process. An app can have one or more instances/processes to meet the user/customer demands.&lt;/p>
&lt;p>As per 12-factor principles, the application should not store the data in in-memory and it must be saved to a store and use from there. As far as the state concern, your application should store the state in the database instead of in memory of the process.&lt;/p>
&lt;p>Avoid using sticky sessions, using sticky sessions are a violation of 12-factor app principles. If you would store the session information, you can choose redis or memcached or any other cache provider based on your requirements.&lt;/p>
&lt;p>By following these, your app can be highly scalable without any impact on the system&lt;/p>
&lt;ul>
&lt;li>Microservices: By adopting the stateless nature of REST, your services can be horizontally scaled as per the needs with zero impact. If your system still requires to maintain the state use the attached resources (redis, Memcached, or datastore) to store the state instead of in-memory.&lt;/li>
&lt;/ul>
&lt;h2 id="7-port-binding-export-services-via-port-binding">7. Port Binding (Export Services Via Port Binding)&lt;/h2>
&lt;p>The twelve-factor app is completely self-contained and doesn&amp;rsquo;t rely on runtime injection of a webserver into the execution environment to create a web-facing service. The web app exports HTTP as a service by binding to a port, and listening to requests coming in on that port.&lt;/p>
&lt;p>In short, this is all about having your application as a standalone instead of deploying them into any of the external web servers.&lt;/p>
&lt;ul>
&lt;li>Microservices: Spring boot is one example of this one. Spring boot by default comes with embedded tomcat, jetty, or undertow.&lt;/li>
&lt;/ul>
&lt;h2 id="8-concurrency-scale-out-via-the-process-model">8. Concurrency (Scale Out Via the Process Model)&lt;/h2>
&lt;p>This talks about scaling the application. Twelve-factor app principles suggest to consider running your application as multiple processes/instances instead of running in one large system. You can still opt-in for threads to improve the concurrent handling of the requests.&lt;/p>
&lt;p>In a nutshell, twelve-factor app principles advocate to opt-in for horizontal scaling instead of vertical scaling.&lt;/p>
&lt;p>(vertical scaling- Add additional hardware to the system&lt;/p>
&lt;p>Horizontal scaling - Add additional instances of the application)&lt;/p>
&lt;ul>
&lt;li>Microservices: By adopting the containerization, applications can be scaled horizontally as per the demands.&lt;/li>
&lt;/ul>
&lt;h2 id="9-disposability-maximize-the-robustness-with-fast-startup-and-graceful-shutdown">9. Disposability (Maximize the Robustness with Fast Startup and Graceful Shutdown)&lt;/h2>
&lt;p>The twelve-factor app&amp;rsquo;s processes are disposable, meaning they can be started or stopped at a moment&amp;rsquo;s notice. When the application is shutting down or starting, an instance should not impact the application state.&lt;/p>
&lt;p>Graceful shutdowns are very important. The system must ensure the correct state.&lt;/p>
&lt;p>The system should not get impacted when new instances are added or takedown the existing instances as per need. This is also known as system disposability.&lt;/p>
&lt;p>Systems do crash due to various reasons. the system should ensure that the impact would be minimal and the application should be stored in a valid state.&lt;/p>
&lt;ul>
&lt;li>Microservices: By adopting the containerization into the deployment process of microservices, your application implicitly follows this principle at a maximum extent. Docker containers can be started or stopped instantly. Storing request, state, or session data in queues or other backing services ensures that a request is handled seamlessly in the event of a container crash.&lt;/li>
&lt;/ul>
&lt;h2 id="10-devprod-parity-keep-development-staging-and-production-as-similar-as-possible">10. Dev/Prod Parity (Keep Development, Staging, and Production as Similar as Possible)&lt;/h2>
&lt;p>The twelve-factor methodology suggests keeping the gap between development and production environment as minimal as possible. This reduces the risks of showing up bugs in a specific environment.&lt;/p>
&lt;p>The twelve-factor developer resists the urge to use different backing services between development and production.&lt;/p>
&lt;ul>
&lt;li>Microservices: This is an inherent feature of the Microservices that is run using the containerization techniques.&lt;/li>
&lt;/ul>
&lt;h2 id="11-logs-treat-logs-as-event-streams">11. Logs (Treat Logs as Event Streams)&lt;/h2>
&lt;p>Logs become paramount in troubleshooting the production issues or understanding the user behavior. Logs provide visibility into the behavior of a running application.&lt;/p>
&lt;p>Twelve-factor app principles advocate separating the log generation and processing the log&amp;rsquo;s information. From the application logs will be written as a standard output and the execution environment takes care of capture, storage, curation, and archival of such stream should be handled by the execution environment.&lt;/p>
&lt;ul>
&lt;li>Microservices: In Microservices, observability is the first-class citizen. Observability can be achieved through using APM tools (ELK, Newrelic, and other tools) or log aggregations tools like Splunk, logs, etc.&lt;/li>
&lt;/ul>
&lt;p>By following the above-mentioned guidelines all you need is to debug an issue is to go to the central dashboard of your tool and search for it.&lt;/p>
&lt;h2 id="12-admin-processes-run-adminmanagement-tasks-as-one-off-processes">12. Admin Processes (Run Admin/Management Tasks as One-Off Processes)&lt;/h2>
&lt;p>There is a number of one-off processes as part of the application deployment like data migration, executing one-off scripts in a specific environment.&lt;/p>
&lt;p>Twelve-factor principles advocates for keeping such administrative tasks as part of the application codebase in the repository. By doing so, one-off scripts follow the same process defined for your codebase.&lt;/p>
&lt;p>Ensure one-off scripts are automated so that you don&amp;rsquo;t need to worry about executing them manually before releasing the build.&lt;/p>
&lt;p>Twelve-factor principles also suggest using the built-in tool of the execution environment to run those scripts on production servers.&lt;/p>
&lt;ul>
&lt;li>Microservices: Containerization also helps here to run the one-off processes as a task and shutdown automatically one done with the implementation.&lt;/li>
&lt;/ul>
&lt;p>That&amp;rsquo;s all for today. Hope you have enjoyed the article. Please share your thoughts or ideas or improvements in the below comments box.&lt;/p></description></item><item><title>Topics: Spring 5.0 Microservice 2nd - Twelve-Factor Apps</title><link>/topics/cloud-native/12-factor-apps/spring-5.0-microservice-2nd-twelve-factor-apps/</link><pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate><guid>/topics/cloud-native/12-factor-apps/spring-5.0-microservice-2nd-twelve-factor-apps/</guid><description>
&lt;blockquote>
&lt;p>Spring 5.0 Microservice 2nd (2017) | 2020-08-30&lt;/p>
&lt;/blockquote>
&lt;h2 id="1-single-code-base">1. Single code base&lt;/h2>
&lt;p>&lt;img src="images/single-code-base.png" alt="">&lt;/p>
&lt;p>Extending the same philosophy for microservices, each microservice should have its own code base, and this code base is not shared with any other microservice. It also means that one microservice will have exactly one code base.&lt;/p>
&lt;h2 id="2-bundle-dependencies">2. Bundle dependencies&lt;/h2>
&lt;h2 id="3-externalizing-configurations">3. Externalizing configurations&lt;/h2>
&lt;p>The Externalize configurations principle gives you an advice to externalize all configuration parameters from the code. An application&amp;rsquo;s configuration parameters vary between environments such as support email IDs or URL of an external system, username, passwords, queue name, and more. These will be different for development, testing, and production. All service configurations should be externalized&lt;/p>
&lt;p>&lt;img src="images/externalizing-configurations.png" alt="">&lt;/p>
&lt;h2 id="4-backing-services-are-addressable">4. Backing services are addressable&lt;/h2>
&lt;p>All backing services should be accessible through an addressable URL. All services need to talk to some external resources during the life cycle of their execution. For example, they could be listening to or sending messages to a messaging system, sending an email, or persisting data to a database. All these services should be reachable through a URL without complex communication requirements&lt;/p>
&lt;p>&lt;img src="images/backing-services-are-addressable.png" alt="">&lt;/p>
&lt;h2 id="5-isolation-between-build-release-and-run">5. Isolation between build, release, and run&lt;/h2>
&lt;p>&lt;img src="images/isolation-between-build-release-and-run.png" alt="">&lt;/p>
&lt;h2 id="6-stateless-shared-nothing-processes">6. Stateless, shared nothing processes&lt;/h2>
&lt;h2 id="7-expose-services-through-port-bindings">7. Expose services through port bindings&lt;/h2>
&lt;p>A Twelve-Factor App ideally does not relay on an external web server. A HTTP listener, such as Tomcat, Jetty, and more, has to be embedded in the service or application itself.&lt;/p>
&lt;h2 id="8-concurrency-for-scale-out">8. Concurrency for scale out&lt;/h2>
&lt;p>In the microservices world, services are designed for a scale out rather than scale up.&lt;/p>
&lt;h2 id="9-disposability-with-minimal-overhead">9. Disposability, with minimal overhead&lt;/h2>
&lt;p>In the microservices context, in order to achieve full automation, it is extremely important to keep the size of the application as thin as possible, with minimal startup and shutdown times. Microservices should also consider lazy loading of objects and data.&lt;/p>
&lt;h2 id="10-development-production-parity">10. Development, production parity&lt;/h2>
&lt;p>The development, production parity principle states the importance of keeping the development and production environments as identical as possible. For example, let&amp;rsquo;s consider an application with multiple services or processes, such as a job scheduler service, cache services, or one or more application services. In a development environment, we tend to run all of them on a single machine. Whereas, in production, we will facilitate independent machines to run each of these processes.&lt;/p>
&lt;h2 id="11-externalizing-logs">11. Externalizing logs&lt;/h2>
&lt;p>If the I/Os are not fast enough in a given infrastructure, they could create a bottleneck. The solution to this is to use a centralized logging framework. &lt;strong>Splunk, greylog, Logstash, Logplex, Loggly&lt;/strong> are some examples of log shipping and analysis tools. The recommended approach is to ship logs to a central repository by tapping the logback appenders and write to one of the shipper&amp;rsquo;s endpoints.&lt;/p>
&lt;p>&lt;img src="images/externalizing-logs.png" alt="">&lt;/p>
&lt;h2 id="12-package-admin-processes">12. Package admin processes&lt;/h2>
&lt;p>Apart from application requests, most of the applications provision for admin tasks. This principle advices you to target the same release and an identical environment as the long running processes runs to perform these activities. Admin code should also be packaged along with the application code.&lt;/p></description></item><item><title>Topics: Comparing API Architectural Styles: SOAP vs REST vs GraphQL vs RPC</title><link>/topics/api-management/api-architectural-styles/soap-vs-rest-vs-graphql-vs-rpc/</link><pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate><guid>/topics/api-management/api-architectural-styles/soap-vs-rest-vs-graphql-vs-rpc/</guid><description>
&lt;blockquote>
&lt;p>&lt;a href="https://www.altexsoft.com/blog/soap-vs-rest-vs-graphql-vs-rpc/">https://www.altexsoft.com/blog/soap-vs-rest-vs-graphql-vs-rpc/&lt;/a> | 2020-05-29&lt;/p>
&lt;/blockquote>
&lt;p>Two separate applications need an intermediary to talk to each other. So, developers often build bridges – &lt;a href="https://www.altexsoft.com/blog/engineering/what-is-api-definition-types-specifications-documentation/">Application Programming Interfaces&lt;/a> – to allow one system to access the information or functionality of another.&lt;/p>
&lt;p>In order to integrate applications quickly and at scale, APIs are realized using protocols and/or specifications to define the semantics and syntax of the messages passed across the wire. These specifications make up the API architecture.&lt;/p>
&lt;p>Over time, different API architectural styles have been released. Each of them has its own patterns of standardizing data exchange. A pull of choices raises endless debates as to which architectural style is best.&lt;/p>
&lt;p>&lt;img src="images/1.png" alt="API timeline">&lt;/p>
&lt;p>&lt;em>API styles over time, Source:&lt;/em> &lt;a href="https://twitter.com/robdcrowley?lang=en">&lt;em>Rob Crowley&lt;/em>&lt;/a>&lt;/p>
&lt;p>Today, many API consumers refer to REST as “&lt;em>REST in peace&lt;/em>” and cheer for GraphQL, while ten years ago it was a reverse story with REST as the winner to replace SOAP. The problem with these opinions is that they are one-sided picking a technology itself instead of considering how its actual properties and characteristics match the situation at hand.&lt;/p>
&lt;p>In this article, we’ll stay objective and discuss the four major API styles in the order of their appearance, compare their strong and weak sides, and highlight the scenarios where each of them fits best.&lt;/p>
&lt;p>&lt;img src="images/2.png" alt="Four major API styles compared">&lt;/p>
&lt;p>&lt;em>Four major API styles compared&lt;/em>&lt;/p>
&lt;h2 id="1-remote-procedure-call-rpc-invoking-a-function-on-another-system">1. Remote Procedure Call (RPC): invoking a function on another system&lt;/h2>
&lt;p>A &lt;strong>Remote Procedure Call&lt;/strong> is a specification that allows for remote execution of a function in a different context. RPC extends the notion of local procedure calling but puts it in the context of an HTTP API.&lt;/p>
&lt;p>Initial XML-RPC was problematic because ensuring data types of XML payloads is tough. So, later an RPC API started using a more concrete &lt;a href="https://www.jsonrpc.org/">JSON-RPC&lt;/a> specification which is considered a simpler alternative to SOAP. &lt;a href="https://grpc.io/">gRPC&lt;/a> is the latest RPC version developed by Google in 2015. With pluggable support for load balancing, tracing, health checking, and authentication, gRPC is well-suited for connecting microservices.&lt;/p>
&lt;h3 id="11-how-rpc-works">1.1 How RPC works&lt;/h3>
&lt;p>A client invokes a remote procedure, serializes the parameters and additional information into a message, and sends the message to a server. On receiving the message, the server deserializes its content, executes the requested operation, and sends a result back to the client. The server stub and client stub take care of the serialization and deserialization of the parameters.&lt;/p>
&lt;p>&lt;img src="images/3.png" alt="Remote Procedure Calling Mechanism">&lt;/p>
&lt;p>&lt;em>Remote Procedure Calling Mechanism, Source:&lt;/em> &lt;a href="https://www.guru99.com/remote-procedure-call-rpc.html#1">&lt;em>Guru99&lt;/em>&lt;/a>&lt;/p>
&lt;h3 id="12-rpc-pros">1.2 RPC Pros&lt;/h3>
&lt;p>&lt;strong>Straightforward and simple interaction.&lt;/strong> RPC uses GET to fetch information and POST for everything else. The mechanics of the interaction between a server and a client come down to calling an endpoint and getting a response.&lt;/p>
&lt;p>&lt;strong>Easy-to-add functions.&lt;/strong> If we get a new requirement for our API, we can easily add another endpoint executing this requirement: 1) Write a new function and throw it behind an endpoint and 2) now a client can hit this endpoint and get the info meeting the set requirement.&lt;/p>
&lt;p>&lt;strong>High performance.&lt;/strong> Lightweight payloads go easy on the network providing high performance, which is important for shared servers and for parallel computations executing on networks of workstations. RPC is able to optimize the network layer and make it very efficient with sending tons of messages per day between different services.&lt;/p>
&lt;h3 id="13-rpc-cons">1.3 RPC Cons&lt;/h3>
&lt;p>&lt;strong>Tight coupling to the underlying system.&lt;/strong> An API’s abstraction level contributes to its reusability. The tighter it is to the underlying system, the less reusable it will be for other systems. RPC’s tight coupling to the underlying system doesn’t allow for an abstraction layer between the functions in the system and the external API. This raises security issues as it’s quite easy to leak implementation details about the underlying system into the API. An RPC’s tight coupling makes scalability requirements and loosely coupled teams hard to achieve. So, the client either worries about any possible side effects of calling a particular endpoint or tries figuring out what endpoint to call because it doesn’t understand how the server is naming its functions.&lt;/p>
&lt;p>&lt;strong>Low discoverability.&lt;/strong> In RPC there’s no way to introspect the API or send a request and start understanding what function to call based on its requests.&lt;/p>
&lt;p>&lt;strong>Function explosion.&lt;/strong> It’s so easy to create new functions. So, instead of editing the existing ones, we create new ones ending up with a huge list of overlapping functions that are hard to understand.&lt;/p>
&lt;h3 id="14-rpc-use-cases">1.4 RPC use cases&lt;/h3>
&lt;p>The RPC pattern started being used around the 80s, but this doesn’t automatically make it obsolete. Big companies like Google, Facebook (&lt;a href="https://thrift.apache.org/">Apache Thrift&lt;/a>), and Twitch (&lt;a href="https://twitchtv.github.io/twirp/docs/intro.html">Twirp&lt;/a>) are using RPC high-performance variates internally to perform extremely high-performance, low-overhead messaging. Their massive microservices systems require internal communication to be clear while arranged in short messages.&lt;/p>
&lt;p>&lt;strong>Command API.&lt;/strong> An RPC is the proper choice for sending commands to a remote system. For instance, a Slack API is very command-focused: Join a channel, leave a channel, send a message. So, the designers of the Slack API modeled it in an RPC-like style making it small, tight, and easy to use.&lt;/p>
&lt;p>&lt;strong>Customer-specific APIs for internal microservices&lt;/strong>. Having direct integration between a single provider and consumer, we don’t want to spend a lot of time transmitting a lot of metadata over the wire, like a REST API does. With high message rate and message performance, gRPC and Twirp are strong cases for microservices. Using HTTP 2 under the hood, gRPC is able to optimize the network layer and make it very efficient with sending tons of messages per day between different services. However, if you’re not aiming at high network performance, but rather at a stable API contact between teams publishing highly distinctive microservices, REST will ensure that.&lt;/p>
&lt;h2 id="2-simple-objects-access-protocol-soap-making-data-available-as-services">2. Simple Objects Access Protocol (SOAP): making data available as services&lt;/h2>
&lt;p>&lt;a href="https://www.altexsoft.com/blog/engineering/what-is-soap-formats-protocols-message-structure-and-how-soap-is-different-from-rest/#soap-use-cases">&lt;strong>SOAP&lt;/strong>&lt;/a> is an XML-formatted, highly standardized web communication protocol. Released by Microsoft a year after XML-RPC, SOAP inherited a lot from it. When REST followed, they were first used in parallel, but soon REST won the popularity contest.&lt;/p>
&lt;h3 id="21-how-soap-works">2.1 How SOAP works&lt;/h3>
&lt;p>XML data format drags behind a lot of formality. Paired with the massive message structure, it makes SOAP the most verbose API style.&lt;/p>
&lt;p>A SOAP message is composed of:&lt;/p>
&lt;ul>
&lt;li>an envelope tag that begins and ends every message,&lt;/li>
&lt;li>a body containing the request or response&lt;/li>
&lt;li>a header if a message must determine any specifics or extra requirements, and&lt;/li>
&lt;li>a fault informing of any errors that can occur throughout the request processing.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="images/4.png" alt="An example of the SOAP message">&lt;/p>
&lt;p>&lt;em>An example of the SOAP message. Source:&lt;/em> &lt;a href="https://www.ibm.com/support/knowledgecenter/en/SSMKHH_10.0.0/com.ibm.etools.mft.doc/ac55780_.htm">&lt;em>IBM&lt;/em>&lt;/a>&lt;/p>
&lt;p>The SOAP API logic is written in Web Service Description Language (WSDL). This API description language defines the endpoints and describes all processes that can be performed. This allows different programming languages and IDEs to quickly set up communication.&lt;/p>
&lt;p>SOAP supports both stateful and stateless messaging. In a stateful scenario, the server stores the received information that can be really heavy. But it’s justified for operations involving multiple parties and complex transactions.&lt;/p>
&lt;h3 id="22-soap-pros">2.2 SOAP Pros&lt;/h3>
&lt;p>&lt;strong>Language- and platform-agnostic.&lt;/strong> The built-in functionality to create web-based services allows SOAP to handle communications and make responses language- and platform-independent.&lt;/p>
&lt;p>&lt;strong>Bound to a variety of transport protocols.&lt;/strong> SOAP is flexible in terms of transfer protocols to accommodate for multiple scenarios.&lt;/p>
&lt;p>&lt;strong>Built-in error handling.&lt;/strong> SOAP API specification allows for returning the Retry XML message with error code and its explanation.&lt;/p>
&lt;p>&lt;strong>A number of security extensions.&lt;/strong> Integrated with the WS-Security protocols, SOAP meets an enterprise-grade transaction quality. It provides privacy and integrity inside the transactions while allowing for encryption on the message level.&lt;/p>
&lt;p>&lt;img src="images/5.png" alt="SOAP message-level security: authentication data in the header element and encrypted body">&lt;/p>
&lt;p>&lt;em>SOAP message-level security: authentication data in the header element and encrypted body&lt;/em>&lt;/p>
&lt;h3 id="23-soap-cons">2.3 SOAP Cons&lt;/h3>
&lt;p>These days, many developers shudder at the idea of having to integrate a SOAP API for several reasons.&lt;/p>
&lt;p>&lt;strong>XML only.&lt;/strong> SOAP messages contain a lot of metadata and only support verbose XML structures for requests and responses.&lt;/p>
&lt;p>&lt;strong>Heavyweight.&lt;/strong> Due to the large size of XML-files, SOAP services require a large bandwidth.&lt;/p>
&lt;p>&lt;strong>Narrowly specialized knowledge.&lt;/strong> Building SOAP API servers requires a deep understanding of all protocols involved and their highly restricted rules.&lt;/p>
&lt;p>&lt;strong>Tedious message updating.&lt;/strong> Requiring additional effort to add or remove the message properties, rigid SOAP schema slows down adoption.&lt;/p>
&lt;h3 id="24-soap-use-cases">2.4 SOAP use cases&lt;/h3>
&lt;p>Right now, the SOAP architecture is most commonly used for internal integration within enterprises or with their trusted partners.&lt;/p>
&lt;p>&lt;strong>Highly secured data transmission.&lt;/strong> SOAP rigid structure, security and authorization capabilities make it the most suitable option for enforcing a formal software contract between API and client while complying with the legal contract between the API provider and API consumer. That’s why financial organizations and other corporate users opt for SOAP.&lt;/p>
&lt;h2 id="3-representational-state-transfer-rest-making-data-available-as-resources">3. Representational state transfer (REST): making data available as resources&lt;/h2>
&lt;p>&lt;strong>REST&lt;/strong> is a self-explanatory API architectural style defined by a set of architectural constraints and intended for wide adoption with many API consumers.&lt;/p>
&lt;p>The most common API style today was originally described in 2000 by Roy Fielding in his &lt;a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm">doctoral dissertation&lt;/a>. REST makes server-side data available representing it in simple formats, often JSON and XML.&lt;/p>
&lt;h3 id="31-how-rest-works">3.1 How REST works&lt;/h3>
&lt;p>REST isn’t as strictly defined as SOAP. RESTful architecture should comply with six architectural constraints:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>uniform interface:&lt;/strong> permitting a uniform way of interacting with a given server regardless of device or application type&lt;/li>
&lt;li>&lt;strong>stateless&lt;/strong>: the necessary state to handle the request as contained within the request itself and without the server storing anything related to the session&lt;/li>
&lt;li>&lt;strong>caching&lt;/strong>&lt;/li>
&lt;li>&lt;strong>client-server architecture:&lt;/strong> allowing for independent evolution of either side&lt;/li>
&lt;li>&lt;strong>layered system&lt;/strong> of the application&lt;/li>
&lt;li>the ability for servers to &lt;strong>provide executable code&lt;/strong> to the client&lt;/li>
&lt;/ul>
&lt;p>In fact, some services are RESTful only to a degree. They have RPC style at the core, break down larger services into resources, and use HTTP infrastructure efficiently. But the key part is using hypermedia aka HATEOAS, short for &lt;a href="https://en.wikipedia.org/wiki/HATEOAS">Hypertext As The Engine of Application State&lt;/a>. Basically, it means that with each response, a REST API provides metadata linking to all the related info about how to use the API. That’s what enables decoupling the client and the server. As a result, both API provider and API consumer can evolve independently without hindering their communication.&lt;/p>
&lt;p>&lt;img src="images/6.png" alt="Richardson Maturity Model as a goalpost to achieving truly complete and useful APIs">&lt;/p>
&lt;p>&lt;em>Richardson Maturity Model as a goalpost to achieving truly complete and useful APIs, Source:&lt;/em> &lt;a href="https://nordicapis.com/what-is-the-richardson-maturity-model/">&lt;em>Kristopher Sandoval&lt;/em>&lt;/a>&lt;/p>
&lt;p>&lt;em>“HATEOAS is a key feature of REST. It’s really what makes REST REST. Since most people don’t use HATEOAS, they are actually using HTTP RPC,”&lt;/em> that’s some radical opinion expressed on &lt;a href="https://www.reddit.com/r/golang/comments/7qvi0w/twirp_a_sweet_new_rpc_framework_for_go_twitch_blog/dstkrnm/">Reddit&lt;/a>. Indeed, HATEOAS is the most mature version of REST. However, it’s difficult to achieve requiring much more advanced and intelligent API clients than those typically used and built today. So, even really good REST APIs today don’t always do it. This is why HATEOAS mainly serves as a vision for the long term development of a RESTful API design.&lt;/p>
&lt;p>There really may be a gray zone between REST and RPC, when a service implements some features of REST and some of RPC. REST is based on the resource or noun instead of action or verb-based.&lt;/p>
&lt;p>&lt;img src="images/7.png" alt="Opposing operations in verb-centric RPC to the ones in noun-centric REST">&lt;/p>
&lt;p>&lt;em>Opposing operations in verb-centric RPC to the ones in noun-centric REST&lt;/em>&lt;/p>
&lt;p>In REST, things are done using HTTP methods such as GET, POST, PUT, DELETE, OPTIONS, and, hopefully, PATCH.&lt;/p>
&lt;p>&lt;img src="images/8.png" alt="REST API">&lt;/p>
&lt;p>&lt;em>Source: Thomas Davis&lt;/em>&lt;/p>
&lt;h3 id="32-rest-pros">3.2 REST Pros&lt;/h3>
&lt;p>&lt;strong>Decoupled client and server.&lt;/strong> Decoupling the client and the server as much as possible, REST allows for a better abstraction than RPC. A system with abstraction levels is able to encapsulate its details to better identify and sustain its properties. This makes a REST API flexible enough to evolve over time while remaining a stable system.&lt;/p>
&lt;p>&lt;strong>Discoverability.&lt;/strong> Communication between the client and server describes everything so that no external documentation is required to understand how to interact with the REST API.&lt;/p>
&lt;p>&lt;strong>Cache-friendly.&lt;/strong> Reusing a lot of HTTP tools, REST is the only style that allows caching data on the HTTP level. In contrast, caching implementation on any other API will require configuring an additional cache module.&lt;/p>
&lt;p>&lt;strong>Multiple formats support.&lt;/strong> The ability to support multiple formats for storing and exchanging data is one of the reasons REST is currently a prevailing choice for building public APIs.&lt;/p>
&lt;h3 id="33-rest-cons">3.3 REST Cons:&lt;/h3>
&lt;p>&lt;strong>No single REST structure.&lt;/strong> There’s no exact right way to build a REST API. How to model resources and which resources to model will depend on each scenario. This makes REST simple in theory, but difficult in practice.&lt;/p>
&lt;p>&lt;strong>Big payloads.&lt;/strong> REST returns a lot of rich metadata so that the client can understand everything necessary about the state of the application just from its responses. And this chattiness is no big deal for a big network pipe with lots of bandwidth capacity. But that’s not always the case. This was the key driving factor for Facebook coming up with the description of GraphQL style in 2012.&lt;/p>
&lt;p>&lt;strong>Over- and under-fetching problems.&lt;/strong> Containing either too much data or not enough of it, REST responses often create the need for another request.&lt;/p>
&lt;h3 id="34-rest-use-cases">3.4 REST use cases&lt;/h3>
&lt;p>&lt;strong>Management APIs.&lt;/strong> APIs focused on managing objects in a system and intended for many consumers are the most common API type. REST helps such APIs to have strong discoverability, good documentation, and it fits this object model well.&lt;/p>
&lt;p>&lt;strong>Simple resource-driven apps.&lt;/strong> REST is a valuable approach for connecting resource-driven apps that don’t need flexibility in queries.&lt;/p>
&lt;h2 id="4-graphql-querying-just-the-needed-data">4. GraphQL: querying just the needed data&lt;/h2>
&lt;p>It takes a number of calls to the REST API for it to return the needed staff. So GraphQL was invented to be a game-changer.&lt;/p>
&lt;p>&lt;a href="https://www.altexsoft.com/blog/engineering/graphql-core-features-architecture-pros-and-cons/">&lt;strong>GraphQL&lt;/strong>&lt;/a> is a syntax that describes how to make a precise data request. Implementing GraphQL is worth it for an application’s data model with a lot of complex entities referencing each other.&lt;/p>
&lt;p>&lt;img src="images/9.png" alt="How to retrieve only the needed data from the GraphQL endpoint">&lt;/p>
&lt;p>&lt;em>How to retrieve only the needed data from the GraphQL endpoint, Source:&lt;/em> &lt;a href="https://medium.com/@mohittikoo/rest-vs-graphql-will-graphql-do-to-rest-what-xml-did-to-json-c99e4fa639c3">&lt;em>Mohit Tikoo&lt;/em>&lt;/a>&lt;/p>
&lt;p>These days the GraphQL ecosystem is expanding with libraries and powerful tools like Apollo, GraphiQL, and GraphQL Explorer.&lt;/p>
&lt;h3 id="41-how-graphql-works">4.1 How GraphQL works&lt;/h3>
&lt;p>GraphQL starts with building a &lt;em>schema,&lt;/em> which is a description of all the queries you can possibly make in a GraphQL API and all the &lt;em>types&lt;/em> that they return. Schema-building is hard as it requires strong typing in the Schema Definition Language (SDL).&lt;/p>
&lt;p>Having the schema before querying, a client can validate their query against making sure the server will be able to respond to it. On reaching the backend application, a GraphQL operation is interpreted against the entire schema, and resolved with data for the frontend application. Sending one massive query to the server, the API returns a JSON response with exactly the shape of the data we asked for.&lt;/p>
&lt;p>&lt;img src="images/10.png" alt="Query execution in GraphQL">&lt;/p>
&lt;p>&lt;em>Query execution in GraphQL, Source:&lt;/em> &lt;a href="https://www.apollographql.com/blog/graphql-explained-5844742f195e">&lt;em>Jonas Helfer&lt;/em>&lt;/a>&lt;/p>
&lt;p>In addition to the RESTful CRUD operations, GraphQL has &lt;em>subscriptions&lt;/em> allowing for real-time notifications from the server.&lt;/p>
&lt;h3 id="42-graphql-pros">4.2 GraphQL Pros&lt;/h3>
&lt;p>&lt;strong>Typed schema.&lt;/strong> GraphQL publishes in advance what it can do, which improves its discoverability. By pointing a client at the GraphQL API, we can find out what queries are available.&lt;/p>
&lt;p>&lt;strong>Fits graph-like data very well.&lt;/strong> Data that goes far into linked relations but not good for flat data.&lt;/p>
&lt;p>&lt;strong>No versioning.&lt;/strong> The best practice with versioning is not to version the API at all.&lt;/p>
&lt;p>While REST offers multiple API versions, GraphQL uses a single, evolving version that gives continuous access to new features and contributes to cleaner, more maintainable server code.&lt;/p>
&lt;p>&lt;strong>Detailed error messages.&lt;/strong> In a similar fashion to SOAP, GraphQL provides details to errors that occurred. Its error message includes all the resolvers and refers to the exact query part at fault.&lt;/p>
&lt;p>&lt;strong>Flexible permissions.&lt;/strong> GraphQL allows for selectively exposing certain functions while preserving private information. Meanwhile, REST architecture doesn’t reveal data in portions. It’s either all or nothing.&lt;/p>
&lt;h3 id="43-graphql-cons">4.3 GraphQL Cons&lt;/h3>
&lt;p>&lt;strong>Performance issues.&lt;/strong> GraphQL trades off complexity for its power. Having too many nested fields in one request can lead to system overload. So, REST remains a better option for complex queries.&lt;/p>
&lt;p>&lt;strong>Caching complexity.&lt;/strong> As GraphQL isn’t reusing HTTP caching semantics, it requires a custom caching effort.&lt;/p>
&lt;p>&lt;strong>A lot of pre-development education.&lt;/strong> Not having enough time to figure out GraphQL niche operations and SDL, many projects decide to follow the well-known path of REST.&lt;/p>
&lt;h3 id="44-graphql-use-cases">4.4 GraphQL use cases&lt;/h3>
&lt;p>&lt;strong>Mobile API.&lt;/strong> In this case, network performance and single message payload optimization is important. So, GraphQL offers a more efficient data loading for mobile devices.&lt;/p>
&lt;p>&lt;strong>Complex systems and microservices.&lt;/strong> GraphQL is able to hide the complexity of multiple systems integration behind its API. Aggregating data from multiple places, it merges them into one global schema. This is particularly relevant for &lt;a href="https://www.altexsoft.com/whitepapers/legacy-system-modernization-how-to-transform-the-enterprise-for-digital-future/">legacy infrastructures&lt;/a> or third-party APIs that have expanded over time.&lt;/p>
&lt;h2 id="5-which-api-pattern-fits-your-use-case-best">5. Which API pattern fits your use case best?&lt;/h2>
&lt;p>Every API project has different requirements and needs. Usually, the architectural choice depends on&lt;/p>
&lt;ul>
&lt;li>the programming language in use,&lt;/li>
&lt;li>the environment in which you’re developing, and&lt;/li>
&lt;li>the resources you have to spare, both human and financial.&lt;/li>
&lt;/ul>
&lt;p>Knowing all the tradeoffs that go into each design style, API designers can pick the one that’s going to fit the project best.&lt;/p>
&lt;p>With its tight coupling, RPC works for internal microservices but it’s not an option for a strong external API or an API service.&lt;/p>
&lt;p>SOAP is troublesome but its rich security features remain irreplaceable for billing operations, booking systems, and payments.&lt;/p>
&lt;p>REST has the highest abstraction and best modeling of the API. But it tends to be heavier on the wire and chattier – a downside if you’re working on mobile.&lt;/p>
&lt;p>GraphQL is a big step forward in terms of data fetching but not everyone has enough time and effort to get the hang of it.&lt;/p>
&lt;p>At the end of the day, it makes sense to try a few small use cases with a particular style, and see if it fits your use case and solves your problems. If it does, try expanding and see if it fits more use cases.&lt;/p></description></item></channel></rss>